{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.1.4 tzdata-2023.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jPCgwUw-ho90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 1, Loss: 0.17776905000209808\n",
      "Epoch: 1, Validation Loss: 0.012542091310024261\n",
      "Epoch: 2, Batch: 1, Loss: 0.03256154805421829\n",
      "Epoch: 2, Validation Loss: 0.02199721336364746\n",
      "Epoch: 3, Batch: 1, Loss: 0.04129542410373688\n",
      "Epoch: 3, Validation Loss: 0.039320189505815506\n",
      "Epoch: 4, Batch: 1, Loss: 0.03632071241736412\n",
      "Epoch: 4, Validation Loss: 0.004913962446153164\n",
      "Epoch: 5, Batch: 1, Loss: 0.05836314707994461\n",
      "Epoch: 5, Validation Loss: 0.01823289692401886\n",
      "Epoch: 6, Batch: 1, Loss: 0.02373502030968666\n",
      "Epoch: 6, Validation Loss: 0.03409358859062195\n",
      "Epoch: 7, Batch: 1, Loss: 0.04893311485648155\n",
      "Epoch: 7, Validation Loss: 0.03554613143205643\n",
      "Epoch: 8, Batch: 1, Loss: 0.03209806606173515\n",
      "Epoch: 8, Validation Loss: 0.0038462996017187834\n",
      "Epoch: 9, Batch: 1, Loss: 0.01797446236014366\n",
      "Epoch: 9, Validation Loss: 0.02861448936164379\n",
      "Epoch: 10, Batch: 1, Loss: 0.026404354721307755\n",
      "Epoch: 10, Validation Loss: 0.036693040281534195\n",
      "Epoch: 11, Batch: 1, Loss: 0.016026761382818222\n",
      "Epoch: 11, Validation Loss: 0.013619344681501389\n",
      "Epoch: 12, Batch: 1, Loss: 0.03616691753268242\n",
      "Epoch: 12, Validation Loss: 0.005956066772341728\n",
      "Epoch: 13, Batch: 1, Loss: 0.016482533887028694\n",
      "Epoch: 13, Validation Loss: 0.03549397736787796\n",
      "Epoch: 14, Batch: 1, Loss: 0.02989199385046959\n",
      "Epoch: 14, Validation Loss: 0.01809174194931984\n",
      "Epoch: 15, Batch: 1, Loss: 0.024926526471972466\n",
      "Epoch: 15, Validation Loss: 0.004646295681595802\n",
      "Epoch: 16, Batch: 1, Loss: 0.016903072595596313\n",
      "Epoch: 16, Validation Loss: 0.011340633034706116\n",
      "Epoch: 17, Batch: 1, Loss: 0.016384730115532875\n",
      "Epoch: 17, Validation Loss: 0.014332819730043411\n",
      "Epoch: 18, Batch: 1, Loss: 0.020988179370760918\n",
      "Epoch: 18, Validation Loss: 0.008150173351168633\n",
      "Epoch: 19, Batch: 1, Loss: 0.025112826377153397\n",
      "Epoch: 19, Validation Loss: 0.007782336324453354\n",
      "Epoch: 20, Batch: 1, Loss: 0.018521109595894814\n",
      "Epoch: 20, Validation Loss: 0.014484195969998837\n",
      "Epoch: 21, Batch: 1, Loss: 0.026635073125362396\n",
      "Epoch: 21, Validation Loss: 0.013527821749448776\n",
      "Epoch: 22, Batch: 1, Loss: 0.01465162169188261\n",
      "Epoch: 22, Validation Loss: 0.011458981782197952\n",
      "Epoch: 23, Batch: 1, Loss: 0.012398782186210155\n",
      "Epoch: 23, Validation Loss: 0.009422007948160172\n",
      "Epoch: 24, Batch: 1, Loss: 0.017379526048898697\n",
      "Epoch: 24, Validation Loss: 0.008660504594445229\n",
      "Epoch: 25, Batch: 1, Loss: 0.02395467460155487\n",
      "Epoch: 25, Validation Loss: 0.011606404557824135\n",
      "Epoch: 26, Batch: 1, Loss: 0.023553557693958282\n",
      "Epoch: 26, Validation Loss: 0.010114898905158043\n",
      "Epoch: 27, Batch: 1, Loss: 0.022320905700325966\n",
      "Epoch: 27, Validation Loss: 0.008298918604850769\n",
      "Epoch: 28, Batch: 1, Loss: 0.016340769827365875\n",
      "Epoch: 28, Validation Loss: 0.013412835076451302\n",
      "Epoch: 29, Batch: 1, Loss: 0.01756894960999489\n",
      "Epoch: 29, Validation Loss: 0.007750031538307667\n",
      "Epoch: 30, Batch: 1, Loss: 0.019562609493732452\n",
      "Epoch: 30, Validation Loss: 0.01685752533376217\n",
      "Epoch: 31, Batch: 1, Loss: 0.01964416168630123\n",
      "Epoch: 31, Validation Loss: 0.00657314620912075\n",
      "Epoch: 32, Batch: 1, Loss: 0.02355775237083435\n",
      "Epoch: 32, Validation Loss: 0.009798990562558174\n",
      "Epoch: 33, Batch: 1, Loss: 0.009194944053888321\n",
      "Epoch: 33, Validation Loss: 0.010395115241408348\n",
      "Epoch: 34, Batch: 1, Loss: 0.015075404196977615\n",
      "Epoch: 34, Validation Loss: 0.009687802754342556\n",
      "Epoch: 35, Batch: 1, Loss: 0.02162243239581585\n",
      "Epoch: 35, Validation Loss: 0.007750550284981728\n",
      "Epoch: 36, Batch: 1, Loss: 0.015802225098013878\n",
      "Epoch: 36, Validation Loss: 0.008631322532892227\n",
      "Epoch: 37, Batch: 1, Loss: 0.022416459396481514\n",
      "Epoch: 37, Validation Loss: 0.01067478395998478\n",
      "Epoch: 38, Batch: 1, Loss: 0.01362835057079792\n",
      "Epoch: 38, Validation Loss: 0.010598557069897652\n",
      "Epoch: 39, Batch: 1, Loss: 0.012791721150279045\n",
      "Epoch: 39, Validation Loss: 0.00866328738629818\n",
      "Epoch: 40, Batch: 1, Loss: 0.018801437690854073\n",
      "Epoch: 40, Validation Loss: 0.0065792459063231945\n",
      "Epoch: 41, Batch: 1, Loss: 0.015642547979950905\n",
      "Epoch: 41, Validation Loss: 0.013475773856043816\n",
      "Epoch: 42, Batch: 1, Loss: 0.012795445509254932\n",
      "Epoch: 42, Validation Loss: 0.01015945803374052\n",
      "Epoch: 43, Batch: 1, Loss: 0.015413301065564156\n",
      "Epoch: 43, Validation Loss: 0.0053879632614552975\n",
      "Epoch: 44, Batch: 1, Loss: 0.015994125977158546\n",
      "Epoch: 44, Validation Loss: 0.01599302515387535\n",
      "Epoch: 45, Batch: 1, Loss: 0.012962562963366508\n",
      "Epoch: 45, Validation Loss: 0.009219684638082981\n",
      "Epoch: 46, Batch: 1, Loss: 0.015100568532943726\n",
      "Epoch: 46, Validation Loss: 0.015208158642053604\n",
      "Epoch: 47, Batch: 1, Loss: 0.014476695097982883\n",
      "Epoch: 47, Validation Loss: 0.010387430898845196\n",
      "Epoch: 48, Batch: 1, Loss: 0.015666954219341278\n",
      "Epoch: 48, Validation Loss: 0.01017424650490284\n",
      "Epoch: 49, Batch: 1, Loss: 0.014911191537976265\n",
      "Epoch: 49, Validation Loss: 0.0029201065190136433\n",
      "Epoch: 50, Batch: 1, Loss: 0.01841338910162449\n",
      "Epoch: 50, Validation Loss: 0.021347856149077415\n",
      "Epoch: 51, Batch: 1, Loss: 0.008566873148083687\n",
      "Epoch: 51, Validation Loss: 0.00616993336006999\n",
      "Epoch: 52, Batch: 1, Loss: 0.01605120673775673\n",
      "Epoch: 52, Validation Loss: 0.014859895221889019\n",
      "Epoch: 53, Batch: 1, Loss: 0.007207756396383047\n",
      "Epoch: 53, Validation Loss: 0.010697726160287857\n",
      "Epoch: 54, Batch: 1, Loss: 0.014379514381289482\n",
      "Epoch: 54, Validation Loss: 0.008819329552352428\n",
      "Epoch: 55, Batch: 1, Loss: 0.01357134897261858\n",
      "Epoch: 55, Validation Loss: 0.014292649924755096\n",
      "Epoch: 56, Batch: 1, Loss: 0.010449783876538277\n",
      "Epoch: 56, Validation Loss: 0.01337493397295475\n",
      "Epoch: 57, Batch: 1, Loss: 0.021407006308436394\n",
      "Epoch: 57, Validation Loss: 0.008906081318855286\n",
      "Epoch: 58, Batch: 1, Loss: 0.025534221902489662\n",
      "Epoch: 58, Validation Loss: 0.008044838905334473\n",
      "Epoch: 59, Batch: 1, Loss: 0.023709099739789963\n",
      "Epoch: 59, Validation Loss: 0.020918479189276695\n",
      "Epoch: 60, Batch: 1, Loss: 0.013282406143844128\n",
      "Epoch: 60, Validation Loss: 0.007235588505864143\n",
      "Epoch: 61, Batch: 1, Loss: 0.009791390970349312\n",
      "Epoch: 61, Validation Loss: 0.012673928402364254\n",
      "Epoch: 62, Batch: 1, Loss: 0.016371233388781548\n",
      "Epoch: 62, Validation Loss: 0.014363477937877178\n",
      "Epoch: 63, Batch: 1, Loss: 0.009362597018480301\n",
      "Epoch: 63, Validation Loss: 0.00643658172339201\n",
      "Epoch: 64, Batch: 1, Loss: 0.011887152679264545\n",
      "Epoch: 64, Validation Loss: 0.015834607183933258\n",
      "Epoch: 65, Batch: 1, Loss: 0.012146616354584694\n",
      "Epoch: 65, Validation Loss: 0.020092464983463287\n",
      "Epoch: 66, Batch: 1, Loss: 0.02263396978378296\n",
      "Epoch: 66, Validation Loss: 0.020869262516498566\n",
      "Epoch: 67, Batch: 1, Loss: 0.014727387577295303\n",
      "Epoch: 67, Validation Loss: 0.009664205834269524\n",
      "Epoch: 68, Batch: 1, Loss: 0.02152971550822258\n",
      "Epoch: 68, Validation Loss: 0.01276236679404974\n",
      "Epoch: 69, Batch: 1, Loss: 0.00789837446063757\n",
      "Epoch: 69, Validation Loss: 0.013806551694869995\n",
      "Epoch: 70, Batch: 1, Loss: 0.008059174753725529\n",
      "Epoch: 70, Validation Loss: 0.011082695797085762\n",
      "Test Loss: 0.028416287153959274\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, label_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.label_file = label_file\n",
    "        self.transform = transform\n",
    "\n",
    "        # Read the labels from the Excel file\n",
    "        self.labels = pd.read_excel(label_file)\n",
    "\n",
    "        # Get the list of JPEG files in the root directory\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.jpeg')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image file name\n",
    "        image_file = self.image_files[idx]\n",
    "\n",
    "        # Read the image from the file\n",
    "        image = Image.open(os.path.join(self.root_dir, image_file)).convert('RGB')\n",
    "\n",
    "        # Apply the transform to the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get the label for the image\n",
    "        label =torch.tensor(self.labels.values).T[idx+1]/100\n",
    "\n",
    "        # Return the image and the label\n",
    "        return image.float(), label.float()\n",
    "\n",
    "\n",
    "\n",
    "# Define the ResNet50 model\n",
    "resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze the ResNet50 model parameters\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add a custom fully connected layer on top of the ResNet50 model\n",
    "resnet50.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=2048, out_features=500),\n",
    "     nn.Linear(in_features=500, out_features=50),\n",
    "    nn.Linear(in_features=50, out_features=20),\n",
    "    nn.Linear(in_features=20, out_features=6),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model = resnet50\n",
    "# Move the model to GPU if available\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model= nn.DataParallel(model,device_ids=[0,1])\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(resnet50.parameters(), lr=0.001)\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize((1000, 1000)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Create the custom dataset\n",
    "dataset = CustomDataset(root_dir='/workspace/low_fine/',\n",
    "                        label_file='/workspace/low_fine/select_low_fine.xlsx', transform=transform)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = int(0.05 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=5, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)\n",
    "\n",
    "\n",
    "#Train the model\n",
    "num_epochs = 70\n",
    "for epoch in range(num_epochs):\n",
    "    # Train the model for one epoch\n",
    "    resnet50.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # Move the inputs and targets to the GPU\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch: {epoch+1}, Batch: {batch_idx+1}, Loss: {loss.item()}')\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    resnet50.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # Move the inputs and targets to the GPU\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = resnet50(inputs)\n",
    "\n",
    "            # Compute the loss\n",
    "            val_loss += criterion(outputs, targets).item()\n",
    "\n",
    "    # Print the validation loss\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Epoch: {epoch+1}, Validation Loss: {val_loss}')\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    # Avoid division by zero\n",
    "    y_true = torch.clamp(y_true, min=1e-8)\n",
    "    # Compute the absolute percentage error\n",
    "    ape = torch.abs((y_true - y_pred) / y_true)\n",
    "    # Return the mean over all predictions\n",
    "    return torch.mean(ape)\n",
    "\n",
    "# Test the model on the test set\n",
    "resnet50.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        # Move the inputs and targets to the GPU\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = resnet50(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        test_loss += criterion(outputs, targets).item()\n",
    "\n",
    "    # Print the test loss\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f'Test Loss: {test_loss}')\n",
    "torch.save(model.state_dict(), 'resnet_mlp_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet_mlp_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lpn7ooDrmLUt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.028416287153959274\n",
      "Test MAPE: 34.75172805786133\n"
     ]
    }
   ],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    # Avoid division by zero\n",
    "    y_true = torch.clamp(y_true, min=1e-8)\n",
    "    # Compute the absolute percentage error\n",
    "    ape = torch.abs((y_true - y_pred) / y_true)*100\n",
    "    # Return the mean over all predictions\n",
    "    return torch.mean(ape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    test_mape = 0.0\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        # Move the inputs and targets to the GPU\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = resnet50(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        test_loss += criterion(outputs, targets).item()\n",
    "        # Compute the MAPE\n",
    "        test_mape += mape(targets, outputs).item()\n",
    "\n",
    "    # Print the test loss and MAPE\n",
    "    test_loss /= len(test_loader)\n",
    "    test_mape /= len(test_loader)\n",
    "    print(f'Test Loss: {test_loss}')\n",
    "    print(f'Test MAPE: {test_mape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
